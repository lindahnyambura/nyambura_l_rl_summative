{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMGnEUoyJR2d2n79vlh1LIL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lindahnyambura/nyambura_l_rl_summative/blob/main/training/pg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Fgcd0uTr_y8M"
      },
      "outputs": [],
      "source": [
        "# clone repo\n",
        "!git clone https://github.com/lindahnyambura/nyambura_l_rl_summative.git\n",
        "%cd nyambura_l_rl_summative\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "GDRIVE = \"/content/gdrive/MyDrive/rl_summative\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEt4LHa5AnxK",
        "outputId": "87d6e451-fedf-43e3-8360-3352e85946b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/nyambura_l_rl_summative\n",
        "!git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VXNb-0XHxqP",
        "outputId": "09f56120-dd0e-4d8b-fd26-428abc6c40a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nyambura_l_rl_summative\n",
            "From https://github.com/lindahnyambura/nyambura_l_rl_summative\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training PPO**"
      ],
      "metadata": {
        "id": "getyt-R4VZLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "sys.path.append(\".\")\n",
        "\n",
        "from training.pg_training import PGTrainingManager, HP_GRID\n",
        "\n",
        "# PPO 150 k steps\n",
        "mgr = PGTrainingManager(\n",
        "    log_dir=f\"{GDRIVE}/logs/ppo\",\n",
        "    model_dir=f\"{GDRIVE}/models/ppo\"\n",
        ")\n",
        "mgr.train(\"ppo_default\", HP_GRID[\"ppo_default\"], total_timesteps=150_000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cE_HGw49BEXL",
        "outputId": "79e6b765-146b-4565-fe47-573e0a8559ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:636: UserWarning: \u001b[33mWARN: Overriding environment NairobiProtestEnv-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training PPO with config: ppo_default\n",
            "============================================================\n",
            "Using cuda device\n",
            "Logging to /content/gdrive/MyDrive/rl_summative/logs/ppo/tensorboard/PPO_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 565      |\n",
            "|    ep_rew_mean     | 493      |\n",
            "| time/              |          |\n",
            "|    fps             | 243      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 67       |\n",
            "|    total_timesteps | 16384    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 566         |\n",
            "|    ep_rew_mean          | 513         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 222         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 147         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009450545 |\n",
            "|    clip_fraction        | 0.102       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | 0.0468      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00866     |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00445    |\n",
            "|    value_loss           | 0.183       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 525         |\n",
            "|    ep_rew_mean          | 487         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 217         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 225         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010897452 |\n",
            "|    clip_fraction        | 0.113       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.77       |\n",
            "|    explained_variance   | 0.372       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.025      |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00481    |\n",
            "|    value_loss           | 0.0744      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 519         |\n",
            "|    ep_rew_mean          | 501         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 215         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 303         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008200251 |\n",
            "|    clip_fraction        | 0.0825      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.76       |\n",
            "|    explained_variance   | 0.62        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0191     |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00503    |\n",
            "|    value_loss           | 0.115       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 502         |\n",
            "|    ep_rew_mean          | 494         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 214         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 381         |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008822908 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0.745       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0295      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00582    |\n",
            "|    value_loss           | 0.0644      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 535         |\n",
            "|    ep_rew_mean          | 549         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 214         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 458         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008451033 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0.707       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00454     |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00697    |\n",
            "|    value_loss           | 0.0623      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 588         |\n",
            "|    ep_rew_mean          | 599         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 214         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 535         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008043209 |\n",
            "|    clip_fraction        | 0.0776      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0.618       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0234      |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00589    |\n",
            "|    value_loss           | 0.0816      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=1276.60 +/- 460.30\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 1.28e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 120000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010460965 |\n",
            "|    clip_fraction        | 0.127       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 0.812       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0121      |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0089     |\n",
            "|    value_loss           | 0.0556      |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 646      |\n",
            "|    ep_rew_mean     | 678      |\n",
            "| time/              |          |\n",
            "|    fps             | 193      |\n",
            "|    iterations      | 8        |\n",
            "|    time_elapsed    | 678      |\n",
            "|    total_timesteps | 131072   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 715         |\n",
            "|    ep_rew_mean          | 755         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 194         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 756         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008387189 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0.814       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00903     |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00658    |\n",
            "|    value_loss           | 0.0631      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 730         |\n",
            "|    ep_rew_mean          | 798         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 196         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 834         |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007986571 |\n",
            "|    clip_fraction        | 0.0872      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 0.613       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.031      |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00501    |\n",
            "|    value_loss           | 0.0427      |\n",
            "-----------------------------------------\n",
            "PPO ppo_default finished in 846.4s.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7d55f8dab950>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training A2C**"
      ],
      "metadata": {
        "id": "Ix3pDFNuVeTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "sys.path.append(\".\")\n",
        "\n",
        "from training.pg_training import PGTrainingManager, HP_GRID\n",
        "\n",
        "# A2C 150 k steps\n",
        "mgr = PGTrainingManager(\n",
        "    log_dir=f\"{GDRIVE}/logs/a2c\",\n",
        "    model_dir=f\"{GDRIVE}/models/a2c\"\n",
        ")\n",
        "mgr.train(\"a2c_default\", HP_GRID[\"a2c_default\"], total_timesteps=150_000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dgETuUhQJ3BR",
        "outputId": "d48314d9-c5b9-448a-ae00-a4affe699358"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:636: UserWarning: \u001b[33mWARN: Overriding environment NairobiProtestEnv-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training A2C with config: a2c_default\n",
            "============================================================\n",
            "Using cuda device\n",
            "Logging to /content/gdrive/MyDrive/rl_summative/logs/a2c/tensorboard/A2C_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 268      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.896   |\n",
            "|    explained_variance | 0.853    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | -0.101   |\n",
            "|    value_loss         | 0.293    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 541      |\n",
            "|    ep_rew_mean        | 562      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.36    |\n",
            "|    explained_variance | 0.999    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | 0.00486  |\n",
            "|    value_loss         | 0.000401 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 641      |\n",
            "|    ep_rew_mean        | 655      |\n",
            "| time/                 |          |\n",
            "|    fps                | 222      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 53       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.54    |\n",
            "|    explained_variance | 0.986    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 0.0777   |\n",
            "|    value_loss         | 0.0107   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 725      |\n",
            "|    ep_rew_mean        | 737      |\n",
            "| time/                 |          |\n",
            "|    fps                | 226      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 70       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.68    |\n",
            "|    explained_variance | 0.993    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 0.00429  |\n",
            "|    value_loss         | 0.000753 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 778      |\n",
            "|    ep_rew_mean        | 779      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 87       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.68    |\n",
            "|    explained_variance | 0.981    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.235    |\n",
            "|    value_loss         | 0.0588   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 800      |\n",
            "|    ep_rew_mean        | 795      |\n",
            "| time/                 |          |\n",
            "|    fps                | 226      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 106      |\n",
            "|    total_timesteps    | 24000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.72    |\n",
            "|    explained_variance | 0.998    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.0329   |\n",
            "|    value_loss         | 0.00758  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 777      |\n",
            "|    ep_rew_mean        | 763      |\n",
            "| time/                 |          |\n",
            "|    fps                | 227      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 123      |\n",
            "|    total_timesteps    | 28000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.76    |\n",
            "|    explained_variance | 0.997    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 0.0406   |\n",
            "|    value_loss         | 0.00112  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 762      |\n",
            "|    ep_rew_mean        | 747      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 139      |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.74    |\n",
            "|    explained_variance | -0.0141  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | -0.511   |\n",
            "|    value_loss         | 1.09     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 728      |\n",
            "|    ep_rew_mean        | 710      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 157      |\n",
            "|    total_timesteps    | 36000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.72    |\n",
            "|    explained_variance | 0.928    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -0.133   |\n",
            "|    value_loss         | 0.031    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 720      |\n",
            "|    ep_rew_mean        | 701      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 174      |\n",
            "|    total_timesteps    | 40000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.69    |\n",
            "|    explained_variance | 0.988    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.0172   |\n",
            "|    value_loss         | 0.000328 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 750      |\n",
            "|    ep_rew_mean        | 734      |\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 191      |\n",
            "|    total_timesteps    | 44000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.69    |\n",
            "|    explained_variance | 0.925    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -0.0227  |\n",
            "|    value_loss         | 0.00435  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 754      |\n",
            "|    ep_rew_mean        | 739      |\n",
            "| time/                 |          |\n",
            "|    fps                | 230      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 208      |\n",
            "|    total_timesteps    | 48000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.73    |\n",
            "|    explained_variance | 0.994    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -0.00205 |\n",
            "|    value_loss         | 0.000456 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 775      |\n",
            "|    ep_rew_mean        | 762      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 227      |\n",
            "|    total_timesteps    | 52000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.74    |\n",
            "|    explained_variance | 0.427    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | -1.09    |\n",
            "|    value_loss         | 2.36     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 755      |\n",
            "|    ep_rew_mean        | 741      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 245      |\n",
            "|    total_timesteps    | 56000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.73    |\n",
            "|    explained_variance | 0.994    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -0.00104 |\n",
            "|    value_loss         | 0.000502 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 742      |\n",
            "|    ep_rew_mean        | 727      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 262      |\n",
            "|    total_timesteps    | 60000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.71    |\n",
            "|    explained_variance | 0.972    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 0.0141   |\n",
            "|    value_loss         | 0.000373 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 720      |\n",
            "|    ep_rew_mean        | 705      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 279      |\n",
            "|    total_timesteps    | 64000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.75    |\n",
            "|    explained_variance | 0.97     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.0515   |\n",
            "|    value_loss         | 0.00349  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 726      |\n",
            "|    ep_rew_mean        | 711      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 297      |\n",
            "|    total_timesteps    | 68000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.77    |\n",
            "|    explained_variance | 0.94     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.0163   |\n",
            "|    value_loss         | 0.000295 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 712      |\n",
            "|    ep_rew_mean        | 699      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 314      |\n",
            "|    total_timesteps    | 72000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.57    |\n",
            "|    explained_variance | 0.847    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.0865   |\n",
            "|    value_loss         | 0.162    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 723      |\n",
            "|    ep_rew_mean        | 706      |\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 331      |\n",
            "|    total_timesteps    | 76000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.19    |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -0.00265 |\n",
            "|    value_loss         | 0.00353  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 699      |\n",
            "|    ep_rew_mean        | 688      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 349      |\n",
            "|    total_timesteps    | 80000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.57    |\n",
            "|    explained_variance | 0.998    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -0.014   |\n",
            "|    value_loss         | 0.00834  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 688      |\n",
            "|    ep_rew_mean        | 679      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 366      |\n",
            "|    total_timesteps    | 84000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.7     |\n",
            "|    explained_variance | 0.955    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 0.0124   |\n",
            "|    value_loss         | 0.000749 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 665      |\n",
            "|    ep_rew_mean        | 659      |\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 384      |\n",
            "|    total_timesteps    | 88000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.62    |\n",
            "|    explained_variance | 0.944    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | 0.0396   |\n",
            "|    value_loss         | 0.00952  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 652      |\n",
            "|    ep_rew_mean        | 642      |\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 401      |\n",
            "|    total_timesteps    | 92000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.75    |\n",
            "|    explained_variance | 0.911    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.0339   |\n",
            "|    value_loss         | 0.000692 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 671      |\n",
            "|    ep_rew_mean        | 666      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 419      |\n",
            "|    total_timesteps    | 96000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.7     |\n",
            "|    explained_variance | 0.972    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.0235   |\n",
            "|    value_loss         | 0.00103  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 660      |\n",
            "|    ep_rew_mean        | 656      |\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 436      |\n",
            "|    total_timesteps    | 100000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.62    |\n",
            "|    explained_variance | 0.973    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.0283   |\n",
            "|    value_loss         | 0.00146  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 656       |\n",
            "|    ep_rew_mean        | 653       |\n",
            "| time/                 |           |\n",
            "|    fps                | 229       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 453       |\n",
            "|    total_timesteps    | 104000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.69     |\n",
            "|    explained_variance | 0.977     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | -0.000716 |\n",
            "|    value_loss         | 0.00035   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 627      |\n",
            "|    ep_rew_mean        | 624      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 471      |\n",
            "|    total_timesteps    | 108000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.822    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | -0.00567 |\n",
            "|    value_loss         | 0.00136  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 611      |\n",
            "|    ep_rew_mean        | 608      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 489      |\n",
            "|    total_timesteps    | 112000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.67    |\n",
            "|    explained_variance | 0.968    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 0.0414   |\n",
            "|    value_loss         | 0.00242  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 606      |\n",
            "|    ep_rew_mean        | 603      |\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 506      |\n",
            "|    total_timesteps    | 116000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.57    |\n",
            "|    explained_variance | 0.999    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | 0.00671  |\n",
            "|    value_loss         | 0.00507  |\n",
            "------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=999.49 +/- 0.78\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | 999      |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 120000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.73    |\n",
            "|    explained_variance | 0.955    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | -0.0102  |\n",
            "|    value_loss         | 0.00527  |\n",
            "------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 611      |\n",
            "|    ep_rew_mean     | 605      |\n",
            "| time/              |          |\n",
            "|    fps             | 202      |\n",
            "|    iterations      | 3000     |\n",
            "|    time_elapsed    | 591      |\n",
            "|    total_timesteps | 120000   |\n",
            "---------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 623      |\n",
            "|    ep_rew_mean        | 623      |\n",
            "| time/                 |          |\n",
            "|    fps                | 203      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 609      |\n",
            "|    total_timesteps    | 124000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.73    |\n",
            "|    explained_variance | 0.996    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | -0.0191  |\n",
            "|    value_loss         | 0.000393 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 631      |\n",
            "|    ep_rew_mean        | 630      |\n",
            "| time/                 |          |\n",
            "|    fps                | 204      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 626      |\n",
            "|    total_timesteps    | 128000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.69    |\n",
            "|    explained_variance | 0.759    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | 0.138    |\n",
            "|    value_loss         | 0.148    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 635      |\n",
            "|    ep_rew_mean        | 636      |\n",
            "| time/                 |          |\n",
            "|    fps                | 205      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 643      |\n",
            "|    total_timesteps    | 132000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.53    |\n",
            "|    explained_variance | 0.99     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | -0.00124 |\n",
            "|    value_loss         | 0.00345  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 631      |\n",
            "|    ep_rew_mean        | 638      |\n",
            "| time/                 |          |\n",
            "|    fps                | 205      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 660      |\n",
            "|    total_timesteps    | 136000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.02    |\n",
            "|    explained_variance | 0.999    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | -0.0221  |\n",
            "|    value_loss         | 0.00123  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 636      |\n",
            "|    ep_rew_mean        | 649      |\n",
            "| time/                 |          |\n",
            "|    fps                | 206      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 678      |\n",
            "|    total_timesteps    | 140000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.13    |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | -0.012   |\n",
            "|    value_loss         | 0.00125  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 647      |\n",
            "|    ep_rew_mean        | 664      |\n",
            "| time/                 |          |\n",
            "|    fps                | 206      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 695      |\n",
            "|    total_timesteps    | 144000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.26    |\n",
            "|    explained_variance | 0.999    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | -0.0167  |\n",
            "|    value_loss         | 0.00178  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 650      |\n",
            "|    ep_rew_mean        | 673      |\n",
            "| time/                 |          |\n",
            "|    fps                | 207      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 712      |\n",
            "|    total_timesteps    | 148000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.23    |\n",
            "|    explained_variance | 0.72     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | -1.03    |\n",
            "|    value_loss         | 2.38     |\n",
            "------------------------------------\n",
            "A2C a2c_default finished in 721.9s.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.a2c.a2c.A2C at 0x7e589875d710>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training REINFORCE**"
      ],
      "metadata": {
        "id": "VKMU0_pIVkxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "sys.path.append(\".\")\n",
        "\n",
        "from training.pg_training import PGTrainingManager, HP_GRID\n",
        "\n",
        "# REINFORCE 150 k steps\n",
        "mgr = PGTrainingManager(\n",
        "    log_dir=f\"{GDRIVE}/logs/reinforce\",\n",
        "    model_dir=f\"{GDRIVE}/models/reinforce\"\n",
        ")\n",
        "mgr.train(\"reinforce\", HP_GRID[\"reinforce\"], total_timesteps=150_000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rXLhn7XfN3Ys",
        "outputId": "50d90f0a-553f-41f1-9439-569277e9a205"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:636: UserWarning: \u001b[33mWARN: Overriding environment NairobiProtestEnv-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training REINFORCE with config: reinforce\n",
            "============================================================\n",
            "Using cuda device\n",
            "Logging to /content/gdrive/MyDrive/rl_summative/logs/reinforce/tensorboard/A2C_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 129      |\n",
            "|    ep_rew_mean        | 138      |\n",
            "| time/                 |          |\n",
            "|    fps                | 202      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.7     |\n",
            "|    explained_variance | 0.813    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | -0.23    |\n",
            "|    value_loss         | 1.02     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 447      |\n",
            "|    ep_rew_mean        | 432      |\n",
            "| time/                 |          |\n",
            "|    fps                | 220      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.72    |\n",
            "|    explained_variance | 0.999    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -0.181   |\n",
            "|    value_loss         | 0.0206   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 426      |\n",
            "|    ep_rew_mean        | 410      |\n",
            "| time/                 |          |\n",
            "|    fps                | 225      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 53       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.73    |\n",
            "|    explained_variance | 0.981    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -0.0364  |\n",
            "|    value_loss         | 0.000692 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 478      |\n",
            "|    ep_rew_mean        | 452      |\n",
            "| time/                 |          |\n",
            "|    fps                | 227      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 70       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.74    |\n",
            "|    explained_variance | 0.951    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 0.0228   |\n",
            "|    value_loss         | 0.000385 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 548      |\n",
            "|    ep_rew_mean        | 521      |\n",
            "| time/                 |          |\n",
            "|    fps                | 227      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 87       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.58    |\n",
            "|    explained_variance | 0.938    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | -0.104   |\n",
            "|    value_loss         | 0.0935   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 565       |\n",
            "|    ep_rew_mean        | 541       |\n",
            "| time/                 |           |\n",
            "|    fps                | 230       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.77     |\n",
            "|    explained_variance | 0.809     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -0.000529 |\n",
            "|    value_loss         | 0.00171   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 626      |\n",
            "|    ep_rew_mean        | 598      |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 120      |\n",
            "|    total_timesteps    | 28000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.72    |\n",
            "|    explained_variance | 0.991    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | -0.0224  |\n",
            "|    value_loss         | 0.000691 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 643      |\n",
            "|    ep_rew_mean        | 616      |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 138      |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0.995    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.0181   |\n",
            "|    value_loss         | 0.000868 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 638      |\n",
            "|    ep_rew_mean        | 613      |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 155      |\n",
            "|    total_timesteps    | 36000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.971    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -0.0283  |\n",
            "|    value_loss         | 0.00229  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 637      |\n",
            "|    ep_rew_mean        | 613      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 172      |\n",
            "|    total_timesteps    | 40000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.74    |\n",
            "|    explained_variance | 0.972    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -0.00718 |\n",
            "|    value_loss         | 0.000238 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 654      |\n",
            "|    ep_rew_mean        | 631      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 189      |\n",
            "|    total_timesteps    | 44000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.68    |\n",
            "|    explained_variance | 0.911    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -0.0165  |\n",
            "|    value_loss         | 0.00754  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 652      |\n",
            "|    ep_rew_mean        | 630      |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 207      |\n",
            "|    total_timesteps    | 48000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.74    |\n",
            "|    explained_variance | 0.994    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 0.0217   |\n",
            "|    value_loss         | 0.000621 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 647      |\n",
            "|    ep_rew_mean        | 628      |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 224      |\n",
            "|    total_timesteps    | 52000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.72    |\n",
            "|    explained_variance | 0.988    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.0134   |\n",
            "|    value_loss         | 0.000471 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 649      |\n",
            "|    ep_rew_mean        | 631      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 240      |\n",
            "|    total_timesteps    | 56000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.77    |\n",
            "|    explained_variance | 0.991    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 0.0118   |\n",
            "|    value_loss         | 0.000489 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 660      |\n",
            "|    ep_rew_mean        | 641      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 258      |\n",
            "|    total_timesteps    | 60000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.75    |\n",
            "|    explained_variance | 0.847    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -0.0115  |\n",
            "|    value_loss         | 0.000653 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 660      |\n",
            "|    ep_rew_mean        | 642      |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 276      |\n",
            "|    total_timesteps    | 64000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.67    |\n",
            "|    explained_variance | 0.991    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.0197   |\n",
            "|    value_loss         | 0.000904 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 666      |\n",
            "|    ep_rew_mean        | 647      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 292      |\n",
            "|    total_timesteps    | 68000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.68    |\n",
            "|    explained_variance | 0.971    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.0312   |\n",
            "|    value_loss         | 0.00296  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 684      |\n",
            "|    ep_rew_mean        | 666      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 309      |\n",
            "|    total_timesteps    | 72000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.76    |\n",
            "|    explained_variance | 0.998    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.017    |\n",
            "|    value_loss         | 0.000358 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 709       |\n",
            "|    ep_rew_mean        | 690       |\n",
            "| time/                 |           |\n",
            "|    fps                | 231       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 327       |\n",
            "|    total_timesteps    | 76000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.72     |\n",
            "|    explained_variance | 0.979     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -0.000901 |\n",
            "|    value_loss         | 0.00035   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 710      |\n",
            "|    ep_rew_mean        | 693      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 344      |\n",
            "|    total_timesteps    | 80000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.61    |\n",
            "|    explained_variance | 0.987    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.0102   |\n",
            "|    value_loss         | 0.00144  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 732      |\n",
            "|    ep_rew_mean        | 715      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 361      |\n",
            "|    total_timesteps    | 84000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.75    |\n",
            "|    explained_variance | 0.986    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | -0.00315 |\n",
            "|    value_loss         | 0.000257 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 730      |\n",
            "|    ep_rew_mean        | 713      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 378      |\n",
            "|    total_timesteps    | 88000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.72    |\n",
            "|    explained_variance | 0.98     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | 0.0374   |\n",
            "|    value_loss         | 0.00112  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 727      |\n",
            "|    ep_rew_mean        | 709      |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 396      |\n",
            "|    total_timesteps    | 92000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.77    |\n",
            "|    explained_variance | -0.0123  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | -0.112   |\n",
            "|    value_loss         | 0.331    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 717      |\n",
            "|    ep_rew_mean        | 701      |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 413      |\n",
            "|    total_timesteps    | 96000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.59    |\n",
            "|    explained_variance | 0.983    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | -0.025   |\n",
            "|    value_loss         | 0.000806 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 714      |\n",
            "|    ep_rew_mean        | 700      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 430      |\n",
            "|    total_timesteps    | 100000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.75    |\n",
            "|    explained_variance | 0.974    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | -0.00321 |\n",
            "|    value_loss         | 0.000372 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 717      |\n",
            "|    ep_rew_mean        | 704      |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 448      |\n",
            "|    total_timesteps    | 104000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.73    |\n",
            "|    explained_variance | 0.995    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | -0.0181  |\n",
            "|    value_loss         | 0.000282 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 736      |\n",
            "|    ep_rew_mean        | 723      |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 465      |\n",
            "|    total_timesteps    | 108000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.78    |\n",
            "|    explained_variance | 0.77     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | -0.00456 |\n",
            "|    value_loss         | 0.0005   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 723      |\n",
            "|    ep_rew_mean        | 718      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 482      |\n",
            "|    total_timesteps    | 112000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.21    |\n",
            "|    explained_variance | 0.961    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | -0.194   |\n",
            "|    value_loss         | 0.265    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 707      |\n",
            "|    ep_rew_mean        | 699      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 499      |\n",
            "|    total_timesteps    | 116000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.25    |\n",
            "|    explained_variance | 0.809    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | -0.19    |\n",
            "|    value_loss         | 1.51     |\n",
            "------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=988.09 +/- 24.74\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | 988      |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 120000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.76    |\n",
            "|    explained_variance | 0.988    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | -0.00783 |\n",
            "|    value_loss         | 6.66e-05 |\n",
            "------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 714      |\n",
            "|    ep_rew_mean     | 732      |\n",
            "| time/              |          |\n",
            "|    fps             | 206      |\n",
            "|    iterations      | 3000     |\n",
            "|    time_elapsed    | 582      |\n",
            "|    total_timesteps | 120000   |\n",
            "---------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 720      |\n",
            "|    ep_rew_mean        | 737      |\n",
            "| time/                 |          |\n",
            "|    fps                | 206      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 600      |\n",
            "|    total_timesteps    | 124000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.73    |\n",
            "|    explained_variance | 0.00353  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | -0.332   |\n",
            "|    value_loss         | 0.453    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 721      |\n",
            "|    ep_rew_mean        | 739      |\n",
            "| time/                 |          |\n",
            "|    fps                | 207      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 616      |\n",
            "|    total_timesteps    | 128000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.74    |\n",
            "|    explained_variance | 0.998    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | 0.00162  |\n",
            "|    value_loss         | 4.76e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 727      |\n",
            "|    ep_rew_mean        | 746      |\n",
            "| time/                 |          |\n",
            "|    fps                | 208      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 633      |\n",
            "|    total_timesteps    | 132000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.77    |\n",
            "|    explained_variance | 0.0437   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | -0.747   |\n",
            "|    value_loss         | 1.16     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 705      |\n",
            "|    ep_rew_mean        | 725      |\n",
            "| time/                 |          |\n",
            "|    fps                | 208      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 652      |\n",
            "|    total_timesteps    | 136000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.71    |\n",
            "|    explained_variance | 0.215    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | -0.163   |\n",
            "|    value_loss         | 0.155    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 710      |\n",
            "|    ep_rew_mean        | 733      |\n",
            "| time/                 |          |\n",
            "|    fps                | 209      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 669      |\n",
            "|    total_timesteps    | 140000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.55    |\n",
            "|    explained_variance | 0.0515   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | -0.23    |\n",
            "|    value_loss         | 0.403    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 693      |\n",
            "|    ep_rew_mean        | 723      |\n",
            "| time/                 |          |\n",
            "|    fps                | 209      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 685      |\n",
            "|    total_timesteps    | 144000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.72    |\n",
            "|    explained_variance | 0.975    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | -0.0138  |\n",
            "|    value_loss         | 0.00116  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 662      |\n",
            "|    ep_rew_mean        | 692      |\n",
            "| time/                 |          |\n",
            "|    fps                | 210      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 703      |\n",
            "|    total_timesteps    | 148000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.67    |\n",
            "|    explained_variance | -0.114   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | -0.251   |\n",
            "|    value_loss         | 0.457    |\n",
            "------------------------------------\n",
            "REINFORCE reinforce finished in 711.9s.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.a2c.a2c.A2C at 0x7845243a8610>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluate**"
      ],
      "metadata": {
        "id": "h4wvKFLwVp3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "GDRIVE = \"/content/gdrive/MyDrive/rl_summative\"\n",
        "runs = {\n",
        "    \"DQN\":     f\"{GDRIVE}/logs/dqn/evaluations.npz\",\n",
        "    \"PPO\":     f\"{GDRIVE}/logs/ppo/evaluations.npz\",\n",
        "    \"A2C\":     f\"{GDRIVE}/logs/a2c/evaluations.npz\",\n",
        "    \"REINFORCE\": f\"{GDRIVE}/logs/reinforce/evaluations.npz\",\n",
        "}\n",
        "\n",
        "labels, best_raw, final_raw = [], [], []\n",
        "for name, npz in runs.items():\n",
        "    data = np.load(npz)\n",
        "    raw = data['results'].flatten()     # (n_evals, n_episodes)\n",
        "    labels.append(name)\n",
        "    best_raw.append(raw.max())\n",
        "    final_raw.append(raw[-20:].mean())  # last 20 ep\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "x = np.arange(len(labels))\n",
        "plt.bar(x, best_raw, label='Best raw reward')\n",
        "plt.bar(x, final_raw, label='Final 20-ep mean', alpha=0.7)\n",
        "plt.xticks(x, labels)\n",
        "plt.ylabel('Episode reward (raw)')\n",
        "plt.title('150 k-step comparison')\n",
        "plt.legend()\n",
        "save_path = Path(GDRIVE) / \"plots\" / \"final_comparison.png\"\n",
        "save_path.parent.mkdir(exist_ok=True, parents=True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(save_path, dpi=300)\n",
        "plt.show()\n",
        "print(\"Saved →\", save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "mX2P7QjSUaeU",
        "outputId": "7f354927-de3c-4f84-ca95-e979f0c435a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved → /content/gdrive/MyDrive/rl_summative/plots/final_comparison.png\n"
          ]
        }
      ]
    }
  ]
}